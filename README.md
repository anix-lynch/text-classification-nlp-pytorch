# Text Classification Using PyTorch

This project demonstrates how to build a deep learning-based text classifier using PyTorch. It covers various stages of text preprocessing, feature extraction, model selection, training, and evaluation. Traditional machine learning techniques such as XGBoost, alongside neural networks, are also explored.

## Project Overview

Text classification is a core task in natural language processing (NLP), where we automatically categorize text documents into predefined categories. It has practical applications such as:

- **Sentiment Analysis**: Identifying sentiment in customer reviews.
- **Spam Detection**: Classifying emails as spam or not.
- **Topic Classification**: Categorizing articles into topics like sports or politics.
- **AI-Generated Text Detection**: Distinguishing between human-written and AI-generated text.

In this project, we will:

- Clean and preprocess text data.
- Extract meaningful features from the text.
- Train both traditional machine learning models (like XGBoost) and deep learning models.
- Use pre-trained language models and contextual embeddings.
- Handle imbalanced datasets effectively.

## Key Features

- **Text Preprocessing**: Using libraries like NLTK for tokenization, stemming, and lemmatization.
- **Feature Extraction**: Techniques such as TF-IDF and word embeddings.
- **Machine Learning Models**: Traditional algorithms such as XGBoost.
- **Deep Learning Models**: PyTorch neural networks, pre-trained language models, and contextualized embeddings.
- **Imbalanced Data Handling**: Addressing class imbalance using techniques such as oversampling or class weighting.
